# ğŸ§  IntelliForge â€“ AI Multi-Tool Platform with Multi-LLM + RAG + Local Model Support ğŸš€

A powerful, flexible AI platform that brings **generative AI tools**, **retrieval-augmented generation (RAG)**, and **multi-model chat experiences** into one streamlined web application â€” all while respecting your data privacy and giving you full control.

Run it on your machine with **Ollama**, in the cloud with **OpenAI**, or both â€” and switch between models on the fly with memory **fully preserved**.

---

## ğŸŒŸ Features

### ğŸ” CoreChat â€“ Multi-Model Chatbot with Seamless Switching

* Switch between GPT, Groq, Ollama (and others) **mid-conversation**
* **Persistent memory** across model changes for smooth, coherent chats
* Use your own models locally or cloud services as needed
* Use Completely Free Search Tool (DuckDuckGo + Crawl4ai + Retrieval)
* Great for **model comparison**, **cost efficiency**, and **privacy**

ğŸ“– Learn more about the memory management system in [this blog post](https://medium.com/p/c3364e21b117)

---

### ğŸ“„ RAGSmith â€“ Retrieval-Augmented Generation on Your Data

* Upload your own documents, PDFs, or databases
* Build a smart, context-aware RAG bot with **your content**
* Supports **OpenAI**, **Groq**, and **Ollama** and **GITHUB** for RAG
* Ideal for **teams**, **creators**, or **private enterprises** who need secure document-based AI

---

### âš™ï¸ Additional Highlights

* **Privacy-first**: Keep everything on-device if needed (no data leakage)
* **Vector Database Integration**: Efficient storage & search using ChromaDB
* **Modern UI**: Clean web interface for chatting, configuring, and uploading data
* **Docker Support**: Easy to deploy locally or in the cloud
* **Environment-Based Configuration**: Simple setup for multiple environments

---

## ğŸ› ï¸ Tech Stack

* **Backend**: Python, Flask
* **LLM Integration**: LangChain, OpenAI, Groq, Ollama
* **Vector Search**: ChromaDB, FAISS, Sentence Transformers
* **Frontend**: HTML, JavaScript (minimal UI, fully extendable)
* **Containerization**: Docker
* **Environment Management**: Python-dotenv

---

## ğŸš€ Getting Started

### Prerequisites

* Python 3.11+
* Docker (optional, for containerized deployment)
* API keys for OpenAI, Groq (if using cloud models)
* [Ollama](https://ollama.com/) installed for local models

---

### Installation

1. Clone the repository:

```bash
git clone https://github.com/AmirmahdiAbtl/IntelliForge
cd IntelliForge
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Set up environment variables:

```bash
cp .env.example .env
```

Edit `.env` with your API keys and config.

---

### Running the Application

#### Local Development

```bash
flask run --no-reload
```

---

## ğŸ“š Usage

1. Open your browser: `http://localhost:5000`
2. Start chatting using CoreChat
3. Switch models at any point â€” context is retained
4. Upload files to RAGSmith and query your documents

---

## ğŸ”§ Configuration

Environment variables in `.env`:

* `FLASK_ENV` â€“ development or production
* `OPENAI_API_KEY`
* `GROQ_API_KEY`
* `OLLAMA_HOST` â€“ if using local models
* `CHROMA_DB_PATH`, etc.

---

## ğŸ¤ Contributing

Contributions welcome! Help improve the future of personal AI tools.

1. Fork the repo
2. Create your feature branch (`git checkout -b feature/MyFeature`)
3. Commit your changes
4. Push and open a PR

---

## ğŸ“ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgments

* LangChain â€“ RAG + LLM magic
* OpenAI, Groq, and Ollama â€“ for providing robust LLM APIs
* ChromaDB & FAISS â€“ blazing-fast vector search
* The open-source community!

---

## ğŸ‘¤ Author

**Amirmahdi Aboutalebi**
ğŸ”— [LinkedIn](https://www.linkedin.com/in/amirmahdi-abootalebi/)
ğŸ“‚ [Project Repository](https://github.com/AmirmahdiAbtl/IntelliForge)
ğŸ“ [Blog Post on Memory Handling](https://medium.com/p/c3364e21b117)

---

â­ Star this repo if you like where this project is going â€” and feel free to open an issue or pull request if you have ideas!